
## 신뢰할수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션

많은 어플리케이션은 계산 중심적이기보다 데이터 중심적이다.

### 데이터 시스템에 관한 생각
데이터베이스, 캐시, 검색 색인, 스트림 처리, 일괄 처리 등이 필요하며
성공적으로 데이터 시스템을 추상화해 사용하고 있다.

이것들의 구현 방식은 다 다를 수 있는데 왜 데이터 시스템이라는 포괄적 용어로 묶어야 할까?
분류와 경계가 흐려지고 있는 측면이 있으며 단일 도구로는 더 이상 처리와 저장 모두를 만족시킬 수 없을 정도의 과도하고 광범위한 요구사항을 갖고 있기 때문이기도 하다.

대신 작업은 단일 도구에서 효율적으로 처리할 수 있는 태스크(task)로 나누고 다양한 도구들은 애플리케이션 코드를 활용해 서로 연결한다.


이에 따라 개발자는 애플리케이션 개발자 뿐만 아니라 데이터 시스템 설계자이기도 하다.


신뢰성, 확장성, 유지보수성이라는 큰 세단계를 고려해야하며 이를 쉽게 만들어주는 간단한 해결책은 없다.

하지만 여러 애플리케이션에서 계속 반복되는 특정 패턴과 기술이 있으며, 이후 몇개의 장에서 데이터 시스템 몇가지를 예제로 살펴보고 
이런 목표를 향해 데이터 시스템이 어떻게 작동하는지 분석할 것이다.


### 확장성의 측면에서 부하 성능을 테스트할때


#### 트위터를 예시로 들어보자.

트위터에서는 트윗을 작성하는 기능과

홈 타임라인을 볼 수 있는 대표적인 기능이 존재한다.

단순히 초당 1,2000건 의 쓰기 처리는 상당히 쉬우나 트위터의 확장성 문제는 주로 트윗의 양이 아닌 팬 아웃에 있다.

팬아웃이란 다른 게이트의 출력에 배속된 논리 게이트 입력의 수를 의미하는 것으로 트랜젝션 처리 시스템에서 하나의 수신 요청을 처리하는데 필요한 다른 서비스의 요청 수를 설명하기 위해 사용한다.

즉 트위터에서 개별 사용자는 많은 사용자들을 팔로우하고 많은 사람이 개별 사용자를 팔로우하는 곳에서 문제가 발생한다.

위의 두가지 동작을 구현하는 방식은 크게 두가지가 있다.

첫째로, 트윗 작성은 간단히 새로운 트윗을 트윗 전역 컬렉션에 삽입한다. 사용자가 만일 자신의 홈 타임라인을 요청하면 팔로우하는 모든 사람을 찾고, 이 사람들의 모든 트윗을 찾아 정렬해서 합친다.


이의 쿼리(질의)는 다음과 같을 수 있다.

`SELECT tweet.*, users.* FROM tweets
  JOIN users ON tweets.sender_id = users.id
  JOIN follows ON follows.followee_id = users.id
 WHERE follows.follower_id = current_user`


 하지만 위의 방식을 시스템이 홈 타임라인 질의 부하를 버텨내기 위해 힘든 점이 있다. (특히 데이터가 증가할 수록)
 따라서 평균적으로 트윗 게시 요청량이 홈 타임 라인 읽기 요청량에 비해 수백배 적기 때문에 아래와 같은 방식이 훨씬 잘 동작하고 이 경우 쓰기 시점에 더 많은 일을 하고 읽기 시점에 적은 일을 하는 것이
 더 바람직하기 때문에 구현된 것이다.

 두번째 방식은
 각 수신 사용자용 트윗 우편함처럼 개별 사용자의 홈 타임라인 캐시를 유지하는 것이다. 사용자가 트윗을 작성하면 해당 사용자를 팔로우하는 사람들을 모두 찾고 팔로워 각자의 홈 타임라인 캐시에 새로운 트윗을
 삽입한다. 그러면 홈 타임라인의 읽기 요청은 요청 결과를 미리 계산했기 때문에 비용이 저렴하다.


 그러나 접근 방식 2의 불리한 점은 이제는 트윗 작성이 많은 부가 작업을 필요로 한 다는 점이다.
 평균적으로 트윗이 약 70여명의 팔로워에게 전달되므로 초당 4.6k의 트윗은 홈 타임 라인 캐시에 초당 345k 건의 쓰기가 된다.

 그러나 평균 값은 사용자마다 팔로워 수가 매우 다르다는 점을 가린다.

 즉 일부 사용자는 팔로워가 3천만 명이 넘기 때문에 이것은 단일 트윗이 홈 타임라인에 3천만 건 이상의 쓰기 요청이 될지도 모른다는 의미다. (!)

 적시에 트윗을 전송하는 작업이 (트위터는 5초 이내에 팔로워에게 트윗을 전송하려고 노력한다.) 중요한 과제이다.

 위와 같은 트위터 사례에서 사용자당 팔로워의 분포(해당 사용자의 트윗 빈도에 따라 편중될 수도 있음)는 팬 아웃 부하를 결정하기 때문에 확장성을 논의할때 핵심 부하 매개변수가 된다.

 애플리케이션 마다 특성은 매우 다르지만 부하에 대한 추론에 비슷한 원리를 적용할 수 있다.


 이 내용의 최종 결과는 다음과 같다.

 접근 방식 2가 견고하게 구현되어 트위터는 두 접근 방식의 하이브리드로 바꾸고 있다.
 대부분 사용자의 트윗은 사람들이 작성할 때 홈 타임라인에 펼쳐지지만 팔로워 수가 매우 많은 소수 사용자(인플루언서 등)은 팬 아웃에서 제외된다.
 사용자가 팔로우 한 유명인의 트윗은 별도로 가져와 접근 방식 1처럼 읽는 시점에 사용자의 홈 타임 라인에 합친다.
 이 혼합형 접근 방식은 좋은 성능으로 지속적인 전송이 가능하다.
 조금 더 기술적인 근거를 다룬 후에 12장에서 트위터 사례를 다시 설명한다.

 

#### 성능 기술하기

시스템 부하를 기술하면 부하가 증가시 어떤 일이 발생하는지 조사할 수 있다.

- 부하 매개변수를 증가시키고 시스템 자원(CPU, 메모리, 네트워크 대역폴 등) 은 변경하지 않으면 시스템 성능은 어떻게 영향을 받을지

- 부하 매개변수를 증가시켰을 때 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할지

두 질문 모두 성능 수치가 필요하다.

하둡 같은 일괄 처리 시스템은 보통 처리량 (초당 처리할 수 있는 레코드 수나 일정 크기의 데이터 집합으로 작업을 수행할때 걸리는 전체시간)에 관심을 가진다.

온라인 시스템에서 고객과 직접 맞닿은 시스템에서 더 중요한 사항은 서비스 응답시간이다.

요청이 같더라도 매번 응답 시간이 다를 수 있다.

따라서 응답 시간은 단일 숫자가 아닌 분포로 생각해야 한다.

대부분의 요청은 빠르지만 가끔 꽤 오래 걸리는 특이 값(아웃라이어)가 있을 수 있다.

백그라운드 프로세스의 컨텍스트 스위치, 네트워크 패킷 손실과 TCP 재전송,
가비지 컬렉션 휴지, 디스크에서 읽기를 강제하는 페이지 폴트, 서버 랙의 기계적인 진동이나 다른 여러 원인으로 추가 지연이 생길 수 있다.


평균 응답 시간을 살피는 일은 실제로는 대개 산술 평균으로 이해한다.
(모든 값을 더하고 n으로 나눈 값)
하지만 전형적인 응답 시간을 알고 싶다면 평균은 그다지 좋은 지표가 안디ㅏ.
얼마나 많은 사용자가 실제로 지연을 경험했는지 알려주지 않기 때문이다.

따라서 일반적으로 평균보다 백분위를 사용하는 편이 더 좋다.

가장 빠른 시간 부터 정렬ㄹ하면 중간 지점이 중앙값이 된다.

사용자가 보통 얼마나 오랫동안 기다려야 하는지 알고 싶다면 중앙값이 좋은 지표다.

중앙값은 50분위로서 p50 으로 축약할 수 있다.
중앙값은 단일 요청을 참고한다는 점을 주의하자.

특이 값이 얼마나 좋지 않은지 살펴보려면 상위 백분위를 살펴보는 것도 좋으며
이때 사용하는 백분위는 95분위, 99분위, 99.9분위가 일반적이다.
p95, p99, p999

꼬리 지연 시간(tail latency)로 알려진 상위 백분위 응답 시간은 서비스의 사용자 경험에 직접 영향을 주기 때문에 중요하다.

아마존은 내부 서비스의 응답 시간 요구사항을 99.9분위로 기술한다.

아마존은 응답 시간이 100밀리초 증가하면 판매량이 1% 줄어들고 1초가 늘어지면 고객의 만족도 지표는
16% 줄어드는 현상을 발견했다.

백분위는 서비스 수준 목표와 서비스 수준 협약서에 자주 사용하고 기대 성능과
서비스 가용성을 정의하는 계약서에도 자주 등장한다.

이런 지표는 서비스 클라이언트의 기대치를 설정해 서비스 수준 협약서를 지키지 못하면 고객이 환불을 요구할 수 있게 한다.

큐 대기 지연은 높은 백분위에서 응답 시간의 상당 부분을 차지한다.
서버는 병렬로 소수의 작업만 처리할 수 있기 때문에 (예를 들어 CPU 코어 수에 제한됨)

소수의 느린 요청 처리만으로 후속 요청 처리가 지체된다.

이 현상을 선두 차단이라 한다.

서버에서 후속 요청이 빠르게 처리되더라도 이전 요청이 완료되길 기다리는 시간때문에
클라이언트는 전체적으로 응답 시간이 느리다고 생각할 것이다.

이런 문제 때문에 클라이언트 측 응답 시간 측정이 중요하다.

인위적으로 부하를 생성해 테스트 하는 경우 부하 생성 클라이언트는 응답 시간과
독립적으로 요청을 지속적으로 보내야 한다.

만약 클라이언트가 다음 요청을 보내기 전에 이전 요청이 완료되길 기다리면
테스트에서 인위적으로 대기 시간을 실제보다 더 짧게 만들어 평가를 왜곡한다.

꼬리 지연 증폭 효과
작은 비율의 백엔드 호출만 느려도 최종 사용자 요청이 여러번 백엔드를 호출하면 느린 호출이 발생할 가능성이 증가하고
최종 사용자 요청 중 많은 비율의 응답시간이 결국 느려짐


1분마다 구간 내 중앙값과 다양한 백분위를 계산

알고리즘 사용


### 부하 대응 접근 방식

부하 매개 변수가 어느 정도 증가하더라도 좋은 성능을 유지하려면 어떻게 해야 할까

부하 수준 1단계에 적합한 아키텍처로는 10배의 부하를 대응할 수 없다

급성장하는 서비스를 맡고 있다면 부하 규모의 자릿수가 바뀔 때 마다 혹은 그보다 자주 아키텍처를 재검토 해야할지 모른다.

사람들은 확장성과 관련해 용량 확장(스케일 업)과 스케일 아웃을 말하곤 한다.

다수의 장비에 부하를 분산하는 아키텍처를 비공유 아키텍처라 하고

단일 장비에서 수행될 수 있는 시스템은 보통 간단하지만 고사양 장비는 매우 비싸기 때문에
상당히 집약된 작업 부하는 대개 규모 확장을 피하지 못한다.

현실적으로 좋은 아키텍처는 실용적인 접근 방식의 조합이 필요하다.

예를 들어 적절한 사양의 장비 몇 대가 다량의 낮은 사양 가상 장비보다 여전히 훨씬 간단하고 저렴하다.

일부 시스템은 탄력적이다.

부하 증가를 감지하면 컴퓨팅 자원을 자동으로 추가할 수 있다.

반면 그렇지 않은 시스템은 수동으로 확장해야 한다.

탄력적인 시스템은 부하를 예측할 수 없을 만큼 높은 경우 유용하지만
수동으로 확장하는 시스템이 더 간단하고 운영상 예기치 못한 일이 더 적다.

다수의 장비에 상태 비저장 서비스를 배포하는 일은 상당히 간단하다.

하지만 단일 노드에 상태 유지 (stateful) 데이터 시스템을 분산 설치하는 일은 아주 많은 복잡도가 추가적으로 발생한다.

이런 이유로 확장 비용이나 데이터베이스를 분산으로 만들어야 하는 고가용성 요구가 있을때까지 단일 노드에 데이터베이스를 유지하는 것(용량 확장)이 
최근 까지의 통념이다.


대용량 데이터와 트래픽을 다루지 않는 사용 사례에도 분산 데이터 시스템이 향후 기본 아키텍처로 자리 잡을 가능성이 있다.

이 책의 나머지 부분에서는 많은 종류의 분산 데이터 시스템을 다루고 확장성 뿐만 아니라 손쉬운 사용과 유지보수를 어떻게 달성해야 하는지 설명한다.

대개 대규모로 동작하는 시스템의 아키텍처는 해당 시스템을 사용하는 애플리케이션에 특화되어 있다.

범용적이고 모든 상황에 맞는
one-size-fits-all 확장 아키텍처는 없다.

아키텍처를 결정하는 요소는 읽기의 양, 쓰기의 양,저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항,
접근 패턴 등이 있다.

혹은 이 요소 중 일부 조합에 더 많은 문제가 추가되는 경우도 있다.

예를 들어 각 크기가 1kB인 초당 100,000건의 요청을 처리하도록 설계한 시스템과 각 크기가
2GB인 분당 3건의 요청을 처리하기 위해 설계한 시스템은 서로 같은 데이터 처리량이라고 해도 매우 다르다.

특정 애플리케이션에 적합한 확장성을 갖춘 아키텍처는 주요 동작이 무엇이고 잘하지 않는 동작이
무엇인지에 대한 가정을 바탕으로 구축한다.

이 가정은 곧 부하 매개변수가 된다.

이 가정이 잘못되면 확장에 대한 엔지니어링 노력은 헛수고가 되고 최악의 경우 역효과를 낳는다.
스타트업 초기 단계나 검증되지 않은 제품의 경우 미래를 가정한 부하에 대비해 확장하기 보다는 빠르게 반복해서 제품 기능을 개선하는 작업이
좀 더 중요하다.

### 유지보수성

소프트웨어 비용의 대부분은 초기 개발이 아니라 지속해서 이어지는 유지보수에 들어간다.

희망적인 점은 유지보수 중 고통을 최소화하고 레거시 소프트웨어를 직접 만들지 않게끔 소프트웨어를 설계할 수 있다는 것이다.
아니 꼭 그래야 하며, 그러기 위해 주의를 기울여야 할 소프트웨어 시스템 설계 원칙은 다음 세가지이다.

1. 운용성
   - 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만듬
2. 단순성
   - 시스템에서 복잡도를 최대한 제거하고 새로운 엔지니어가 시스템을 이해하기 쉽게 만듬
3. 발전성
   - 엔지니어가 이후 쉽게 변경할 수 있게 한다. (유연성, 수정 가능성, 적응성)

### 운용성

운영의 편리함 만들기
좋은 운영은 종종 나쁜 소프트웨어의 제약을 피하는 대안이 될 수 있다.
그러나 좋은 소프트웨어라 할지라도 나쁘게 운영할 경우 작동을 신뢰할 수 없다.

운영 중 일부 측면은 자동화할 수 있고 자동화 해야 한다.


시스템 상태를 모니터링, 상태가 좋지 않다면 빠르게 서비스를 복원
장애, 성능 저하 등의 문제 원인 추적
보안 패치 등 포함 최신 상태로 유지
변경 사항을 손상을 입히기 전에 차단
발생 가능한 문제 예측해 문제 발생 전 해결
배포 설정 관리 등을 위한 모범 사례와 도구 마련
유지보수 태스크 수행
설정 변경으로 생기는 보안 등 유지보수
예측 가능한 운영과 안정적 서비스 환경 유지 위한 절차 정의
인사 이동에도 시스템에 대한 조직의 지식 보존

데이터 시스템은 동일 반복 태스크를 쉽게 하기 위해 다음과 같은 일을 포함할 수 있다.
- 좋은 모니터링으로 런타임 동작 및 시스템 내부에 대한 가시성 제공
- 표준 도구를 이용해 자동화와 통합을 위한 우수한 지원 제공
- 개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고 계속해서 운영 가능해야 함
- 좋은 문서와 이해하기 쉬운 운영 모델
- 만족할 만한 기본 동작을 제공, 필요시 기본 값을 다시 정의할 수 있는 자유를 관리자에게 부여
- 적절하게 자기 회복이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함
- 예측 가능하게 동작하고 예기치 않은 상황을 최소화 함

### 단순성: 복잡도 관리

프로젝트가 커짐에 따라 시스템은 매우 복잡하고 이해하기 어려워진다.

복잡도는 다양한 증상으로 나타난다.
상태 공간의 급증, 모듈 간 강한 커플링, 복잡한 의존성, 일관성 없는 명명과 용어,
성능 문제 해결을 목표로 한 해킹, 임시방편으로 문제를 해결한 특수 사례 등이 이런 증상이다.


복잡도 때문에 시스템 유지보수가 어려울 때 예산과 일정이 초과되곤 한다.
복잡한 소프트웨어에서는 변경이 있을 떄 버그가 생길 위험이 더 크다.
개발자가 시스템을 이해하고 추론하기 어려워지면 시스템에 숨겨진 가정과 의도치 않은 결과 및 예기치 않은 상호작용을 간과하기 쉽다.

복잡도를 반대로 줄이면 소프트웨어 유지보수성이 크게 향상된다.
따라서 단순성이 구축하려는 시스템의 핵심 목표여야 한다.

시스템을 단순하게 만든다는 일은 반드시 기능을 줄인다는 의미는 아니며
우발적 복잡도를 줄인다는 뜻일 수 있다.

이는 소프트웨어가 풀어야 할 사용자에게 보이는 문제에 내재하고 있지 않고 구현에서만 발생하는 것으로 정의했다.

이러한 우발적 복잡도를 해결하기 위한 가장 좋은 최상의 도구는 추상화다.

좋은 추상화는 깔끔하고 직관적인 외관 아래로 많은 세부 구현을 숨길 수 있다.
또한 좋은 추상화는 다른 다양한 애플레키엿ㄴ에도 사용 가능하다.
이러한 재사용은 비슷한 기능을 여러 번 재구현하는 것보다 더 효율적일 뿐만 아니라 고품질 소프트웨어로 이어진다.

추상화된 구성 요소의 품질 향상이 이를 사용하는 모든 애플리케이션에 도움이 되기 때문이다.

좋은 추상화를 찾기는 매우 어렵다.
분산 시스템 분야에는 여러 좋은 알고리즘이 있으며 그러나 관리 가능한 수준에서 시스템 복잡도를 유지하는 데 도움이 되는 
추상화로 이런 알고리즘을 묶는 방법은 명확하지 않다.

### 발전성: 변화를 쉽게 만들기

시스템의 요구사항이 영원히 바뀌지 않을 가능성은 매우 적다.
애자일 작업 패턴은 변화에 적응하기 위한 프레임워크를 제공한다.

데이터 시스템 변경을 쉽게 하고 변화된 요구사항에 시스템을 맞추는 방법은 시스템의 간단함과 추상화와
밀접한 관련이 있다.
간단하고 이해하기 쉬운 시스템은 대개 복잡한 시스템보다 수정하기 쉽다.

그러나 이것은 매우 중요한 개념이기 때문에 데이터 시스템 수준에서 민첩성을 언급할 때는 민첩성 대신 다른 단어로
발전성을 사용하겠다.


