
## 저장소와 검색


가장 기본적 수준에서 데이터베이스는 두 가지 작업을 수행한다. 어떤 데이터를 받으면 데이터를 저장하고, 나중에 그 데이터를 요청하면 다시 데이터를 제공한다.

이 장에서는 데이터베이스가 데이터를 저장하는 방법과 데이터를 요청했을때 다시 찾을 수 있는 방법을 설명한다.

데이터 베이스가 저장과 검색을 내부적으로 처리하는 방법을 애플리케이션 개발자가 주의해야 하는 이유는 무엇일까?

주로 애플리케이션 개발자가 처음부터 자신의 저장소 엔진을 구현하는 경우는 거의 없으며 사용 가능한 여러 저장소 엔진 중에 애플리케이션에 적합한 엔진을 선택하는 작업이 필요하다.

특정 작업부하(워크로드) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.

특히 트랜젝션 작업부하에 맞춰 최적화된 저장소 엔진과 분석을 위해 최적화된 엔진 간에는 큰 차이가 있다.

우선 이번 장에서는 익숙한 데이터베이스 종류인 관계형 데이터베이스와 소위 NoSQL라 불리는 데이터베이스에 사용되는 저장소 엔진에 대해 설명한다.

그리고 로그 구조 계열 (log-structured) 저장소 엔진과 B-tree 같은 페이지 지향 계열 저장소 엔진을 검토한다.

### 데이터 베이스를 강력하게 만드는 데이터 구조

세상에서 가장 간단한 데이터베이스를 구상해보자.

두개의 배시 함수로 db_set()과 db_get()을 가진다.

키- 값 저장소를 함수 두개로 구현했으며 db_set key value를 호출하면 데이터베이스에 key와 value를 저장할 수 있다.
키와 값은 어떤 것이든 대부분 가능하다. 예를 들어 값이 json 문서가 될 수 도 있다. db_get key를 호출하면 해당 키와 연관된 가장 최근 값을 찾아 반환할 수 있다.

db_set과 마찬가지로 많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 로그를 사용한다.

실제 데이터베이스는 다뤄야할 더 많은 문제 (동시성 제어, 로그가 영원히 커지지 않게끔 디스크 공간을 회수, 오류 처리, 부분적으로 기록된 레코드 처리)가 있지만 기본 원리는 같다.
로그는 믿기지 않을 정도로 유용하다. 이 사실은 책 나머지 부분에서 여러 번 확인할 수 있다.

반면 db_get 함수는 데이터베이스에 많은 레코드가 있으면 성능이 매우 좋지 않다.
매번 키를 찾을 때마다 db_get은 키가 있는지 찾기 위해 전체 데이터베이스 파일을 처음부터 끝까지 스캔해야 한다.
알고리즘 용어로 검색 비용이 O(n)이다. 데이터베이스의 레코드 수가 두배로 늘면 검색도 두배 오래 걸린다. 바람직하지 않다.

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요하다.
바로 색인이다.
이번 장에서는 다양한 색인 구조를 살펴보고 여러 색인 구조를 비교하는 방법을 알아본다.

색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.
이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는데 도움을 준다. 동일한 데이터를 여러가지 다양한 방법으로 검색하고자 한다면 데이터 각 부분에 여러가지 다양한 색인이 필요하다.

색인은 기본 데이터에서 파생된(primary data) 추가적인 구조다.
많은 데이터베이스는 색인의 추가와 삭제를 허용한다.
이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다.
단지 질의 성능에만 영향을 준다.
추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생한다. 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. 왜냐하면 단순히 파일에 추가하는 작업이 제일 간단한 쓰기 작업이기 때문이다.
어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다.
이는 데이터를 쓸때 마다 매번 색인도 갱신해야 하기 때문이다.

이것은 저장소 시스템에서 중요한 트레이드 오프이다.
색인을 잘 선택했다면 읽기 질의 속도가 향상된다.
하지만 모든 색인은 쓰기 속도를 떨어뜨린다. 이런 이유로 데이터베이스는 보통 자동으로 모든 것을 색인하지 않는다.
애플리케이션 개발자나 데이터베이스 관리자가 애플리케이션의 전형적인 질의 패턴에 대한 지식을 활용해 수동으로 색인을 선택해야 한다. 그래야 필요 이상으로 오버헤드를 발생시키지 않으면서 애플리케이션에 가장 큰 이익을 안겨주는 색인을
선택할 수 있다.


### 해시 색인
키-값 저장소는 사전타입과 매우 유사하다.

앞의 예제처럼 간단하게 파일에 추가하는 방식으로 데이터 저장소를 구성한다고 가정해보자. 그러면 가장 간단하게 가능한 색인 전략은 다음과 같다.
키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다.
바이트 오프셋은 값을 바로 찾을 수 있는 위치이다.

이 방식은 매우 단순해보이지만 실제로 많이 사용하는 접근법이다.

이러한 방식은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다. 예를 들어 키는 고양이 동영상의 URL이고 값은 비디오가 재생된 횟수인 경우다.
이런 유형의 작업부하에서는 쓰기가 아주 많지만 고유 키는 많지 않다. 즉 키당 쓰기 수가 많지만 메모리에 모든 키를 보관할 수 있다.

지금까지 설명한 것처럼 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까?
특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책이다.
특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행한다.
세그먼트 파일들에 대해 컴팩션(compaction)을 수행할 수 있다.

컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.

더욱이 컴팩션은 보통 세그먼트를 더 작게 만들기 때문에 컴팩션을 수행할때 동시에 여러 세그먼트들을 병합할 수 있다.

세그먼트가 쓰여진 후에는 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다.

고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행할 수 있다.

컴팩션을 수행하는 동안 이전 세그먼트 파일을 사용해 읽기와 쓰기 요청의 처리를 정상적으로 계속 수행할 수 있다.

병합 과정이 끝난 이후에는 읽기 요청은 이전 세그먼트 대신 새로 병합한 세그먼트를 사용하게끔 전환한다.

전환 후에는 이전 세그먼트 파일을 간단히 삭제하면 된다.

이제 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다.

키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인한다.
만약 없다면 두 번째 최신 세그먼트 등을 확인한다. 병합 과정을 통해 세그먼트 수를 적게 유지하기 때문에 조회할 때 많은 해시 맵을 확인할 필요가 없다.

실제로는 더 많은 세부 사항들을 고려해야 하는데 중요한 문제 몇가지만 간략히 들자면 다음과 같다.

- 파일 형식
CSV는 로그에 가장 적합한 방식이 아니다. 바이트 단위의 문자열 길이를 부호화한 다음 다음 원시 문자열(이스케이핑할 필요 없이)을 부호화 하는 바이너리 형식을 사용하는 편이 더 빠르고 간단하다.

- 레코드 삭제
키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드(때로는 툼스톤이라 불림)를 추가해야 한다. 로그 세그먼트가 병합될때 툼스톤은 병합 과정에서 삭제된 키의 이전 값을 무시하게 한다.

- 고장 (Crash) 복구
데이터베이스가 재시작되면 인메모리 해시 맵은 손실된다. 원칙적으로는 전체 세그먼트 파일을 처음부터 끝까지 읽고 각 키에 대한 최신 값의 오프셋을 확인해서 각 세그먼트 해시 맵을 복원할 수 있다.
하지만 세그먼트 파일이 크면 해시 맵 복원은 오랜 시간이 걸릴 수 있고 이는 서버 재시작을 고통스럽게 만든다.
비트캐스크는 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게 스냅숏을 디스크에 저장해 복구 속도를 높인다.

- 부분적으로 레코드 쓰기
데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있다. 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지해 무시할 수 있다.

- 동시성 제어
쓰기를 엄격하게 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다. 데이터 파일 세그먼트는 추가 전용이거나 불변(immutable)이므로 다중 스레드로 동시에 읽기를 할 수 있다.


추가 정용 로그는 언뜻보면 낭비처럼 보이며 예전 값을 새로운 값으로 덮어써 정해진 자리에 파일을 갱신하는 방법을 고민해볼 수 있다.
하지만 추가 전용 설계는 여러 측면에서 좋은 설계이다.

- 추가 로그와 세그먼트 병합은 순차적 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 자기 회전 디스크 하드드라이브에서 그렇다. 일부 확장된 순차 쓰기는 플래시 기반 솔리드 스테이트 드라이브(SSD)도 선호한다.
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 예를 들어 값을 덮어쓰는 동안 데이터베이스가 죽는 경우에 대해 걱정할 필요가 없다. 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함께 남겨두기 때문이다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제한 사항이 있다.
- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으로는 디스크에 해시 맵을 유지할 수 있지만 불행히도 디스크 상의 해시 맵에 좋은 성능을 기대하기는 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가
가득찼을때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.

- 해시 테이블은 범의 질의에 효율적이지 않다. 예를들어 kitty00000과 kitty99999사이 모든 키를 쉽게 스캔할 수 없다. 해시 맵에서 모든 개별 키를 조회해야 한다.

다음 절에서는 이런 제한이 없는 색인 구조를 살펴본다.

### SS테이블과 LSM 트리
- 각 로그 구조화 저장소 세그먼트는 키-값 쌍의 연속이다. 이 쌍은 쓰여진 순서대로 나타내며 로그에서 같은 키를 갖는 값 중 나중의 값이 이전 값보다 우선한다.
이제 세그먼트 파일의 형식에 간단한 변경 사항 한가지를 적용해 보자. 변경 요구사항은 일련의 키-값 쌍을 키로 정렬하는 것이다. 언뜻 보기에 이 요구사항은 순차 쓰기를 사용할 수 없게 만드는 것 같지만 잠시 후 이 점에 대해 알아본다.
