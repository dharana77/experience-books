## JVM에서의 lock 동작 방식

- Every Object and Class
    - > associate

Monitor

- Special Room
- Wait Set
- Entry Set

JVM

자바에서 하나의 모니터 락이 존재

뮤텍스, 세마포어

```java
Thread thread1 = new Thread() -> {

	try {
	
		synchronized (mutex) {
		
			System.out.println(“println”);
			
		}
	
	}

}
```

하나의 모니터

요 한개에 대해서 스레드들이 대기

요 스레드들이 대기하는 구조가

special Room에 들어가게 됨

mutex를 점유하게 되는 스레드가

나머지 스레드들이

뮤텍스를 점유하기 위해서는

- Wait Set
- Entry Set이란 자료구조로 대기하게 됨

synchronized

어떤 스레드가 이걸 점유했는지

트래킹하는

임계영역은 하나의 스레드만 실행시킬 수 있는 거죠

나머지는 다른 자료구조에서 기다리는데

special room 에서 작업하다가

코드를 보시면

스레드 1이 있고 스레드 2가 있죠

1가 2가 하는 역할을 보면 간단합니다.

작업하다가 mutext를 점유해서

출력을 하게되고

wait 상태로 스레드1의 상태가 넘어갑니다.

thread2에서는

notifyAll()을 해준다고 하면

waitSet()에 들어가 있는 모든 스레들에게

얘기하는 겁니다

entrySet()으로 들어오게 되는 겁니다

entrySet()으로 들어오면

Mutext를 선택할 수 있는 자격이 주어지고

entrySet() 중 하나가 랜덤으로 뽑아짐

thread1이 시작했고

thread2는 모니터 락에 걸려있다가

스레드1이

어플리케이션 레벨에서 동시성 제어

Synchronized(mutext){

}

- 하나의 코어에서도 동시성 문제는 발생할 수 있음
- 하나의 코어와 하나의 스레드는 다름

Q. monitor에는 wait, entryset 상태의 자료구조가 있다고 하셨는데 최대 몇개까지 대기할 수 있는가?

- 제한은없음

자바 17에서는 가상스레드가 나왔는데

os의 스레드와

jvm스레드와

커널스레드가 1대1 매핑임

자바에서는 따라서 네이티브 스레드로 인지해야하고

어쨌든 운영 스레드다 보니 컨텍스트 스위칭이 발생하고

유저 스레드와 운영스레드가

1:n 매핑이면 관리되는데

자바 JVM 같은 경우는

1대1 매핑이라 막늘리면 안됨

자료구조에 대한 스레드들은 최대

몇까지는 리밋이 없다

다만 스레드가 몇개까지 생성되는 것에 대해서는 리밋이

있을 수 있음

- 결국 스레드를 몇개까지 생성할 수 있냐임

Q. 하나의 코어에서는 병렬 작업이 일어날 수 없음

병렬 작업은 동시에 t1,t2가 실행되야 하는데

코어 하나에서는 하나 밖에 실행될 수 밖에 없으니

동시에 실행될 수 는 없음

Q. JVM 힙사이즈에 따라 동적일지

- 자바에서는 논힙메모리임
- 힙사이즈 보다는 커널 영역의 메모리 사이즈에 따라 다름

Q. entrySet 에서 스레드가 락을 획득하는 순서는

진입순서인가요? 락경쟁을 어떻게 하는지

- 진입순서가 아님
- entrySet에 들어오면 랜덤임
- 다만 힌트를 줄수는 있음
    - setPriority로 우선순위를 설정할 수 있음

Q. 커널 제어를 받으니 힙 맥스 사이즈 걸어도 무한으로 커질 수 있나? OOM 발생여지가 있는지

- 어떤 의미일까요?
- 걸어두어도 스레드들은
- 스레들안에 로컬 변수 사용되도 new를 하게되면
- 그거는 힙에 들어가는거니까 거기에 제한이 걸리지만
- new Thread()만 한다면 커널제어 이기 때문에
- OOM Killer 가 얘를 죽일 수 있습니다
- OOM면 JVM이 얘를 죽이지 않지만
- 코드가 돌아가지 않겠죠
- 그런데 힙스페이스
- 커널 메모리가 OOM이 아니라
- 힙스페이스 제한하면
- 이 프로세스가 왜 이만큼 사용하려하지? 하고 JVM을 kill해버립니다
- OOM Killer 가 종료해버리면 heap dump가 떨어지도 않는거죠
- JVM 이 동작한다면 health check 요청이 살아있다고 오는지
- OOM이 발생했을 때 프로세스는 그래도 떠있다고 하시니
- 헬스체크도 할 수 없죠
- Ok 를 내보내야 하는데 그 과정에서 메모리를 할당할 수 밖에 없기 때문에 에러가 나겠죠 OOM
- 코드에다가 실험을 해보시면 좋아요
- OOM을 던졌는데
- JVM이 종료되는 조건이 있죠
- main thread 와 demon 스레드들이 아닌 스레드들이 다 죽어버리면 JVM이 종료됩니다.
- 그래서 다 죽여버리면 JVM이 죽나 안죽나 테스트해보시면 됩니다.

코드로 작성해서 보여드리는 이유는

책이나 블로그 같은 것들에서 다 확인할 수 있어요

static 은 어떻고

state가 어떻게 넘어가고

글로 보면

코드로 작성할때 내가 알고 있는 이론과 코드로 작성한 것이

동기화되지 않습니다.

그래서 저는 이런 이론들을 공부할때는

눈으로 확인하는 편이에요

상황들을 가정해서

내가 이렇게 작성하면

스레드들 상태들이

이렇게 될 것 같은데

이렇게 눈으로 학습해야

눈으로 확인하셔야

어떻게 코드에 따라 변화할 것인지

예측할 수 있습니다

내가 잘 이해했다고 착각하실수도 있죠

사실 어려운 개념은 아니니까

이렇게 이해했을때 격차가 생깁니다.

## spin lock VS mutex

- 스핀락은 그냥 기다리는 거죠

사실 우리가 이걸 적절하게 잘 써야 합니다

스핀 락을 쓰면 사실 이런거죠

코드로 보여드리면

밑에다 쓰면

이런 식으로 체크하는 거죠

수도 코드로 쓰면

```java
While (“lock 획득했니?” ==- false) {

아니면 while loop를 도는거고

true가 되면 빠져나올 수 있는거고

}
```

이런게 스핀락

장점은

context switching 이 일어나지 않음

처음 위에서 보여준 방식이라면

mutext가 누락 상태가 되어버리면

context switching 이 발생하는데

스핀락은 그렇지 않음

그런데

스핀락을 오랫동안 사용하면

그동안 아무것도 못하니까

점유가 발생하는 거고

너무 조금 사용하면

그래서 timeout 정도가 있음

500ms 가 넘어서도

락을 획득하지못하면

스레드를 재우고

mutext를 사용

쉽게 이런것을 사용하지는 않지만

간혹 있음

제가 일할때의 경험은

예를 들면

스레드 큐를 직접 만들어야 한다면

이런 것들을 쓸수 있죠

스레드 풀에서 하나 가져와야 하는데

스레드 풀의 상태가 다 비워져있어요

그러면 이거를 기다려야 되냐

스핀을 돌면서

내가 스레드를 얻어올 수 있냐

특정시간 안에서는

스레드를 재우는 것보다는

스핀락 돌면서 내가 획득할 수 있으면 획득하고

그것을 처리하면 더 빠르죠

레디스를 통해서

분산락을 개발해봤다면

스핀락이란것을 보셨을 수도 있죠

글로벌 락을 개발한다고 했을때

특정 키가 있으면 락이 걸려잇는거니까

루프 돌면서

레디스와 통신이 너무 많아지는거 아니냐면

레디슨이라는 라이브러리는

스핀락에 대한 오버헤드가 있으니까

pub sub을

스핀락을 걸다가

레디슨 메커니즘이 너무 길어지면

스레드를 재우고

publish를 해가지고 subscribe 하고 있던 애들이

개를 점유하려고 하는거죠

그러면 network IO를 줄일수 있지만

장단점이 있음

짧게 기다릴 수 있는 것은 스핀락이 훨씬 빠름

그다음에

### lock free 알고리즘

모든 동시성 메커니즘은 확인하는거죠

스핀락이든 뮤텍스 이용하는 거든

해당 락을 획득할 수 있을까

점유할수 있을까 하면서

체크하는 것인데

결국은 락개념인것인데

락 프리 알고리즘은 락이 없는 것

cas 연산이라고 보통하는데

compare and set이라고

낙관적인 락의 매커니즘임

로컬에서는 저걸 어떻게 구현하냐면

코드 보시면 알겠지만

private static AtomicLong atomicLong =

new AtomicLong(0);

아토믹 롱을 보시면

compareAndSet이라는게 잇어요

내가 기대하는게 0 이고 기대하는게 1이라는 것

//현재 atomicLong 이 0이면

1로 값을 세팅해줌

보시면 알겠지만 코드 들어가 보시면

어때요 native 메소드죠

하드웨어적으로

assembly어로 되어있죠

동시성 제어를 위해서

명령어 한줄로 제공해줍니다.

이런 것들은 코드에 어셈블리 라인이 두개 이상 들어가버리면

데이터 정합성이 안맞잖아요

그런 것을 하드웨어가 지원해주는 거죠

하드웨어에서 지원해주는 것만 쓸수 있는데 요즘은 다 지원해주니까

고수준의 언어에서도 쓸수 있고

하나의 명령어로 치환해버림

원자적이기 때문에 다른 명령어를 쓸 필요가 없죠

여러 스레드에서 쓰고 싶다

줄세워서

이 연산이 오래걸리고 스레드가 뭐 100개 이상이다면

줄세워서 하기 때문에

느려지는데

Lock-free 알고리즘을 사용하게 되면

lock을 걸지않으므로

1번 값이 0인데 새로운 값인 1로 초기화하겠어

세팅해주면 되는거고

얘가 0이 아니라 다른 값이에요

그러면

compareAndSet은 실패하게 됩니다

리턴 벨류가 boolean

성공하면 true, 실패하면 false

이것을 그러면 while loop 안에 넣어버릴 수 있는 거죠

While(!atomicLong.compareAndSet(0, 1)) {

이게 true 가 될때까지 돌려

}

되게 빠름

lock을 걸필요가 없기 때문에

데이터베이스나 스토리지 레벨로 가면

낙관적인 잠금이 되는 거죠

예를 들면 테이블에다가 버전이라는 컬럼을 두고

버전을 업데이트 시킬때마다

select 어떤 테이블 ‘A’ from where id = ? and version =1;

이라고 해볼수 있죠

그러면

버전은

id는 유니크한 값이니까

버전 1이 있다면 업데이트를 칠수 있는거고

isolation level도 낮춰서 low 락을 걸필요 없이

lock-free 알고리즘을 쓸수도 있는거죠

그런데 항상 좋은 것은 또 아닙니다

낙관적인 잠금이 락을 안거는거니까 더 빠른거 아니냐 하지만

compare And Set이 느릴 때도 있음

결과를 실패시키잖아요

실패시키고 다시 실행시키기 때문에

업데이트가 되게 많은 것에서

CAS 나 낙관적인 락을 쓰면

불필요한 연산을 계속 하게 되는거에요

비관적인 락을 쓰면 불필요한 연산을 할 필요는 없죠

비싼 연산을 하게 되는 거지만

그래서 그걸 고려하셔야 되요

갱신이 많지 않은 데이터다면

낙관적인, 락프리를 사용하는게

갱신이 많은 데이터라면

실패하는 연산이 많아져서 비관적인 잠금보다

느려질 수 있으므로

그런 것을 고려하셔야 합니다.

Q. 낙관적락과 데이터베이스의 skip lock의 차이는

- 낙관적인 락과는 다름
- 락이 걸리지 않은 애들을 갖고 와서 그냥 처리하는 것

Q. redisson 뜯어보면 세마포어 쓰는 것을 알 수 있음

- 세마포어는 뭐고 redisson은 뭐지?
- 왜 세마포어를 사용하지?

Q. (조회수에 대해서는 비관적 락, 낙관적 락을 걸면 성능 문제가 있을 수 있을 것 같아서 싱글 스레드인 레디스를 활용해 카운트를 올리고 스케줄러를 통해서 일정기간 한번의 업데이트를 하는 것을 생각하는데 더 효율적인 방식이 있을지)

싱글스레드를 이용한 방식도 있는데

그게 레디스인거고요

근데 거기서 주의할 점은

redis는 휘발성 메모리이기 때문에

뭔가 한번의 업데이트하기 전에 오류가 발생하면

데이터 유실이 발생할 수 있음

이런 데이터 유실만 잘 관리해주면 더 효율적인 방식일 수 있음

Q. 보통 디비 단의 lock 필요한 환경에서 비관적 락을 걸기 보단 redisson 활용한 분산 락을 활용해 DB/IO 가능한 쓰레드를 제어하는 느낌으로 많이 거는 것 같은데( 거의 표준처럼)

보통 이런 의사결정을 할 때의 기준을 어떻게 정하시나요?

- db는 noSQL을 쓰지 않는 이상 스케일 아웃이 불가능하죠
- RDB 같은 경우는 마스터 슬레이브 구조기 때문에
- 보통은 redis 이용해서 분산 락을 쓰고
- 레디스는 사실 저는 쓰지 않습니다 분산락이 필요할때
- 분산락이 사실 알고리즘이기 때문에
- 구현해서 쓰고
- 메트릭을 쓰고 라이브러리 종속적이기 때문에
- 그리고 redisson 쓰려면 돈내야하거든요

따로 기준을 없어요

redisson 을 쓸 수 있는 환경이라면 당연히 redisson을 사용하는 분산락을 쓰는 편이고요

만약에 쓸 수없는 환경이라면

그럴 때는 옵션이 없죠

디비락을 걸죠

Skip lock, wait lock

isolation level을 조정하거나 이런 것들을 고려해볼 수있을 것 같습니다.

사실 데이터 정합성 설정에 따라 다른 거죠

락을 써서 데이터 정합성을 맞춰야하는데

글로벌하게 공유되어서 여러 서버 인스턴스들이 공유되어야 하는 거다 하면

레디스에서 분산락을 써야 하는 거고

로컬에서만 공유 되야 되는 거다 하면

syncrhonized 를 사용할 수 있는 거고

사례를 들자면

이런게 있을 수 있죠

우리가 서버에서

Health check를 한다고 합시다

헬스 체크를 요 ok냐 fail이냐에 따라서

어드민에서 리모트를 제어할 수 있다고 해봅시다

메인 함수를 컨트롤 하고 생각을 해보면

heatlh = “FAIL”

health = “OK”

여러개의 인스턴스에 대해서 바꾼다면

정확히 안바뀔 수 있죠

이럴 때

synchronized( mutext) {

health = “변수”;

}

이런 식으로 해줘야 겠죠

서버 로컬레벨이 아니라 전서버

전역적인 거다면

글로벌로 가야겠죠

이런 경우가 좀 있죠

mutext, synchronized는 생각보다 종종 씁니다

예를 들어 어떤 컬렉션에 대해서

요즘 concurrentCollection을 쓰기 때문에

안맞을 수 있지만

그런게 없다면

private static Map<String, Object> map = new HashMap<>();

이런 애들에 데이터를 넣었다 빼줬다해야된다고 한다면

syncrhonized를 쓰겠죠

### 얘기를 좀 요약해보면

제가 오늘 설명해드린 얘기를 요약해보면

병렬성과 동시성은 다른 메커니즘이고

같이 쓰고 있지만 용어를

엄연하게 다른 메커니즘이고

동시성은 하나의 코어에서 여러개의 스레드들이 함께 실행되는 것

병렬성은 여러 코어에서 여러 코어가 동시에 실행되는 것이

병렬성

하나의 코어에서 타임을 쪼개 다수 쓰레드로 작업을 수행할때

메모리에 write 하기 전에 로컬에만 갖고 있다는 부분에서

로컬에만 갖고 있다는 건 cpu 레지스터에 갖고 있는 거라고 이해하면 맞을까요?

- cpu 레지스터나 l1,l2 cache 이런데 갖고 있는거죠

제한된 상황에서 어플리케이션을 더 고사용성으로 만들기 위한

메커니즘이고

발열이 심하기 때문에

현재 멀티코어로 가는게 정배고

소프트웨어 개발자 엔지니어들은

하드웨어들을 유틸라이즈를 높이기 위해서

코딩을 하는거고

데이터를 공유하지않으면

아무생각없이 병렬 프로그래밍을 할 수 있지만

그것도 정합성 때문에

되게 많은 메커니즘을 공부하죠

다른 프레임워크 언어에서도 비슷한 알고리즘이 쓰이고

자바에서 모니터링이라고 하는 거고

모니터링이라고 하는 것은 원래 존재하는 이론이고

자바에서는 이것을 이용해서

로컬 어플리케이션 레벨에서 사용하는 거고

뮤텍스를 이용하면 잠그는 거니까

줄지어서 처리하는 거고

줄지어서 처리하지 않기 위한 방법은 뭐가 있을까

하드웨어에서 제공하는

CAS 를 사용해서

락 프리 알고리즘으로

하드웨어 명령을 지원받아 좀더 빠르게

동시성 제어를

데이터 정합성을 맞출 수 있다

다만 이도 신의 은총은 아니다

반드시 이해해야 하는 것은

컴퓨터 기술에 관해서는 신의 은총은 절대 없다

락 프리 알고리즘은 데이터 갱신에 대해서는

불필요한 연산이 많을 수 있기 때문에

비관적인 락이 더 좋아요

비관적인 락 자체

로컬에서의 병렬 프로그래밍

데이터 정합성을 맞추기 위한 방법이고

글로벌로 가면

Redisson 분산락을 쓰거나

데이터베이스에 있는 락 개념들을 공부해서 쓰거나

그렇게 해야 합니다

락 개념도 메커니즘을 공부하는게 훨씬 낫습니다

특정 기능을 공부해버리면

스토리지에 못쓰게 됐을때

또 공부해야돼

메커니즘을 알아두면

어떤 라이브러리, 어떤 스토리지를 , 어떤 구조체를 쓰든

구현체이기 때문에 좀더 손쉽게 사용하고 이해할 수 있습니다.

혹시 여기까지 질문이나 궁금하신 점이 있으실까요

JVM 모니터링 할 수 있는 툴도 잘 나와있으니깐

꼭 테스트를 해보세요

분산락 같은 경우는

Redis

distributed lcoks with redis

보시면

어떻게 구현했는지 보실 수 있거든요

분산락에 대해 설명하고

분산락 메커니즘을 이렇게 개발했다

이런 것으로 좀 보면서

키워드들을 다시 좀 더 보는 편이고

JVM 같은 경우는 다 아시겠지만

### 자바 병렬프로그래밍 - 브라이언 게츠

https://product.kyobobook.co.kr/detail/S000000935083

### JVM 밑바닥까지 파헤치기 를 요즘은 보고 있습니다.

Q. 하나의 프로세스에서 모든 코어를 쓰는 옵션을 지양해야 할까요

- 간혹 자바 코드에서도 MAX_CPU_CORE 비슷한 옵션을 본 것 같은데 다 끌어쓰면 다른 프로세스 실행에 제약
- 요즘은 쿠버네티스를 많이 사용해서 JVM 레벨 보다는 인프라 레벨에서 옵션을 많이 넣는 편
- 커널마다 프로세스가 격리되는 컨테이너를 띄워서 사용하기 때문

Q. 쿠버는 몇년 차부터 다뤄보는게 좋을까요? 애마한 질문인 것 같은데..

- 쿠베는 관심있으면 공부하는 것
- 꼭 필요하지 않더라도 컨테이너는 공부해보는 게 좋음

키워드에 대해서 공부

한시간에 다 설명하긴 어려운 주제이므로

어떤 내용들이 있는지

어떤 내용들을 공부해야 하는 지 설명
